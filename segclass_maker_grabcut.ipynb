{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_midpoint_to_corner(bb):\n",
    "    label = bb[0]\n",
    "    x1 = bb[1] - bb[3]/2\n",
    "    x2 = bb[1] + bb[3]/2\n",
    "    y1 = bb[2] - bb[4]/2\n",
    "    y2 = bb[2] + bb[4]/2\n",
    "    # A: area will only be used for sorting\n",
    "    area = bb[3]*bb[4]\n",
    "    corner_list = [label, x1, x2, y1, y2, area]\n",
    "    return np.array(corner_list)\n",
    "\n",
    "def open_yolo_sort(path, image_name):\n",
    "    try:\n",
    "        image = cv2.imread(path + image_name)\n",
    "        shape = image.shape\n",
    "        width = shape[1]\n",
    "        height = shape[0]\n",
    "        label = path + os.path.splitext(image_name)[0] + \".txt\"\n",
    "        boxes = np.genfromtxt(label, delimiter=' ')\n",
    "        bb = boxes\n",
    "        # reshaping the np array is necessary in case a file with a single box is read\n",
    "        boxes = boxes.reshape(boxes.size//5, 5)\n",
    "        #print(boxes.shape)\n",
    "        boxes = np.apply_along_axis(bb_midpoint_to_corner, axis=1, arr=boxes)\n",
    "        # A: sorting by area\n",
    "        boxes = boxes[boxes[:, 5].argsort()]\n",
    "        # A: reversing the sorted list so bigger areas come first\n",
    "        boxes = boxes[::-1]\n",
    "        return image, boxes, width, height\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        print(image_name)\n",
    "        return image, None, None, None\n",
    "    \n",
    "\n",
    "colors = [(162, 0, 255),  # Chave seccionadora lamina (Aberta)\n",
    "         (97, 16, 162),   # Chave seccionadora lamina (Fechada)\n",
    "         (81, 162, 0),    # Chave seccionadora tandem (Aberta)\n",
    "         (48, 97, 165),   # Chave seccionadora tandem (Fechada)\n",
    "         (121, 121, 121), # Disjuntor\n",
    "         (255, 97, 178),  # Fusivel\n",
    "         (154, 32, 121),  # Isolador disco de vidro\n",
    "         (255, 255, 125), # Isolador pino de porcelana\n",
    "         (162, 243, 162), # Mufla\n",
    "         (143, 211, 255), # Para-raio\n",
    "         (40, 0, 186),    # Religador\n",
    "         (255, 182, 0),   # Transformador\n",
    "         (138, 138, 0),   # Transformador de Corrente (TC)\n",
    "         (162, 48, 0),    # Transformador de Potencial (TP)\n",
    "         (162, 0, 96)     # Chave tripolar\n",
    "         ] \n",
    "\n",
    "colors_rgb = []\n",
    "for c in colors:\n",
    "    colors_rgb.append((c[2], c[1], c[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a24c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ITER_COUNT = 10\n",
    "\n",
    "def grabcut(image_path, save_path, image_name, filter_class):\n",
    "    \"\"\"Use Grabcut to create a binary segmentation mask of all objects of a given class in an image,\n",
    "       based on YOLO box annotations.\n",
    "    Param:\n",
    "        image_path: path to the dir where the images are stored\n",
    "        save_path: path to the dir where the masks will be saved\n",
    "        image_name: name for the image proper\n",
    "        filter_class: intex of the class to make a GrabCut mask from.\n",
    "    Returns:\n",
    "        1 if there were any labels of the class from filter list and the mask was made\n",
    "        succesfully, 0 otherwise;\n",
    "        The number of boxes that belonged to filter_class in the image, which may be 0.\n",
    "        An RGB image with shape (image_height, image_width, 3) that is a binary mask, but colored\n",
    "        with the correct object class from the colors global array. The image will be pure black,\n",
    "        if no boxes of filter_class were present.\n",
    "    Based on:\n",
    "        https://stackoverflow.com/questions/12810405/opencv-set-color-to-a-foreground-marked-pixel-gc-pr-fgd\n",
    "        https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html\n",
    "        https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/     \n",
    "    \"\"\"\n",
    "    image, bb, w, h = open_yolo_sort(image_path, image_name)\n",
    "    mask = image.copy()*0\n",
    "    # the mask has to be in grayscale for grabcut to work\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     fig = plt.figure(figsize=(20,20))\n",
    "#     ax = fig.add_subplot(141)\n",
    "#     ax.imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "#     plt.axis('off')\n",
    "    \n",
    "    filter_flag = False\n",
    "    count = 0\n",
    "    if bb is not None:\n",
    "        for label, x1, x2, y1, y2, area in bb:\n",
    "            if label == filter_class:\n",
    "                count += 1\n",
    "                filter_flag = True\n",
    "                rw = (x2*w - x1*w)\n",
    "                rh = (y2*h - y1*h)\n",
    "                # the likely foreground around the center\n",
    "                cv2.rectangle(mask, (int(x1*w), int(y1*h)), (int(x2*w), int(y2*h)), 100, -1)\n",
    "                # the certainly foreground will be the inntermost 20%\n",
    "                cv2.rectangle(mask, (int(x1*w + rw*0.4), int(y1*h + rh*0.4)), (int(x2*w - rw*0.4), int(y2*h - rh*0.4)), 255, -1)\n",
    "    else:\n",
    "        return 0, 0, image.copy()*0\n",
    "        \n",
    "    # grabcut will only be performed if there was any bounding box in the filter list to start with\n",
    "    if filter_flag:\n",
    "        # https://stackoverflow.com/questions/12810405/opencv-set-color-to-a-foreground-marked-pixel-gc-pr-fgd\n",
    "        # https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html\n",
    "        # https://pyimagesearch.com/2020/09/28/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/\n",
    "        # GC_BGD Certainly a background pixel\n",
    "        # GC_FGD Certainly a foreground (object) pixel\n",
    "        # GC_PR_BGD Probably a background pixel\n",
    "        # GC_PR_FGD Probably a foreground pixel\n",
    "        mask[mask == 255] = cv2.GC_FGD    # the 20% innermost\n",
    "        mask[mask == 100] = cv2.GC_PR_FGD # the area around center\n",
    "        mask[mask == 0]   = cv2.GC_BGD    # the black pixels background\n",
    "        gct = np.zeros(image.shape[:2], np.uint8)\n",
    "        bgdModel, fgdModel = np.zeros((1, 65), np.float64), np.zeros((1, 65), np.float64)\n",
    "        (gcMask, bgModel, fgModel) = cv2.grabCut(image, mask, None, bgdModel, fgdModel, _ITER_COUNT, cv2.GC_INIT_WITH_MASK)\n",
    "        outputMask = np.where((gcMask == cv2.GC_BGD) | (gcMask == cv2.GC_PR_BGD), 0, 1)\n",
    "        outputMask = (outputMask * 255).astype(\"uint8\")\n",
    "        \n",
    "#         ax3 = fig.add_subplot(142)\n",
    "#         ax3.imshow(cv2.cvtColor(outputMask, cv2.COLOR_GRAY2BGR))\n",
    "#         plt.axis('off')\n",
    "\n",
    "        output = cv2.cvtColor(outputMask, cv2.COLOR_GRAY2BGR) \n",
    "        output = np.where(output != (0, 0, 0), colors_rgb[filter_class], output)\n",
    "\n",
    "#         ax3 = fig.add_subplot(143)\n",
    "#         ax3.imshow(cv2.cvtColor(output.astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "#         plt.axis('off')\n",
    "        \n",
    "        return 1, count, output\n",
    "    else:\n",
    "        return 0, 0, image.copy()*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42038bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_grabcut_multiclass(image_path, save_path, image_name, filter_list, mask_list):\n",
    "    \"\"\"\n",
    "    Creates a segmentation mask out of independent masks for each class.\n",
    "    Param:\n",
    "        image_path: path to the dir where the images are stored\n",
    "        save_path: path to the dir where the masks will be saved\n",
    "        image_name: name for the image proper\n",
    "        filter_list: array with the labels that will be accounted for\n",
    "        mask_list: array of segmentation masks for each class label. Each is an image with \n",
    "        the same resolution as the one that will be opened using image_path and image_name.\n",
    "    Returns:\n",
    "        Nothing, but it does save the image. If no objects from filter_list were found, a pitch\n",
    "        black image (0, 0, 0) with the same resolution as the one that will be opened using\n",
    "        image_path and image_name will be saved instead.\n",
    "    \"\"\"\n",
    "    image, bb, w, h = open_yolo_sort(image_path, image_name)\n",
    "    gc_mask = image.copy()*0\n",
    "    \n",
    "    if bb is not None:\n",
    "        for label, x1, x2, y1, y2, area in bb:\n",
    "            label = int(label)\n",
    "            if label in filter_list:\n",
    "                mask = mask_list[label]\n",
    "                sx1 = int(x1*w)\n",
    "                sx2 = int(x2*w)\n",
    "                sy1 = int(y1*h)\n",
    "                sy2 = int(y2*h)\n",
    "                gc_mask[sy1:sy2, sx1:sx2][np.where(np.all(mask[sy1:sy2, sx1:sx2] == colors_rgb[label], axis=-1))[:2]] = colors_rgb[label]\n",
    "        cv2.imwrite(save_path + os.path.splitext(image_name)[0] +\".png\", gc_mask)\n",
    "#         fig = plt.figure(figsize=(20,20))\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         test = cv2.cvtColor(gc_mask.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "#         ax.imshow(test)\n",
    "#         plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd6411",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths = [\"/home/jovyan/work/yolo_og/yolov3/Data/15_classes/test/\"]\n",
    "paths = [\"/home/jovyan/work/deeplab/data/train/\"]\n",
    "\n",
    "# filter list está no modo in\n",
    "filter_list = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14] # excluding only porcelain pin insulator\n",
    "save_path = \"../data/14_class/train_gci/\"\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "check_path = os.path.isdir(save_path)\n",
    "if not check_path:\n",
    "    os.makedirs(save_path)\n",
    "    print(\"created folder: \", save_path) \n",
    "    \n",
    "#label_path = \"../data/labels_17class/\"\n",
    "images = 0\n",
    "boxes = 0\n",
    "total_images = 0\n",
    "for image_path in paths:\n",
    "    print(image_path)\n",
    "    file_list = os.path.join(os.path.join(image_path, \"*.*\"))\n",
    "    image_list = []\n",
    "    file_list = glob.glob(file_list)\n",
    "    for name in file_list:\n",
    "        if \"txt\" not in name:\n",
    "            image_list.append(name.split(\"/\")[-1])\n",
    "    total_images += len(image_list)\n",
    "    mask_list = [None]*len(colors)\n",
    "    for file in image_list:\n",
    "        image_increase = True # to only add the image once if a class was in the label list\n",
    "        for object_class in filter_list:\n",
    "#             print(object_class)\n",
    "            im, box_num, mask_list[object_class] = grabcut(image_path, save_path, file, object_class)\n",
    "            if image_increase:\n",
    "                images += im\n",
    "                image_increase = False\n",
    "            boxes += box_num\n",
    "        apply_grabcut_multiclass(image_path, save_path, file, filter_list, mask_list)\n",
    "\n",
    "text = f'Images: {images}\\nBoxes: {boxes}\\nTotal images: {total_images}'\n",
    "print(text)\n",
    "with open(\"../data/14_class/train_gci.txt\", 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
